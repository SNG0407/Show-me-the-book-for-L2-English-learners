ABSTRACT
Virtual Learning Environments (VLEs) became the primary space for
education during the Coronavirus disease (COVID-19) lockdowns. One
of the additions that specifically VR has to offer is its potential to
incorporate some of the qualities that define interpersonal
communication and typically lack in distance-learning VLEs. This study’s
aim is exploration of those qualities to appreciate Virtual Reality
Learning Environments (VRLEs) as a supplementary tool for distance
learning and its impact on knowledge acquisition processes, with the
particular objectives of evaluating usability, usefulness, and realism of
Non-Verbal Cues (NVCs) capture. Toward this end a multi-user VRLE
prototype was developed and utilized for the delivery of a live lecture
by a real professor of a MSc programme. The professor’s body motion
and facial expressions were captured in real-time and solved onto a
high-fidelity avatar. In total, a group of 20 students audited the lecture
via the VRLE and evaluated the modalities and experience offered
compared to conventional VLEs. Additionally, knowledge acquisition
was directly correlated to another group of 20 students, who audited
the same lecture only via conventional VLEs. Evaluation results provide
important insight regarding the learning experience between the two
settings and how incorporation of NVCs can have a positive impact.

Introduction
Virtual Learning Environments (VLEs), integrating several Information and Communication Technologies (ICTs) tools, are becoming commonplace as they provide the option of distance learning (AlAjlan, 2012). With the use of web-conferencing services, such as the Big Blue Button (BBB) [https://
bigbluebutton.org/], VLEs facilitate real-time lectures between remotely located students and educators, as they support real-time voice communication, using Voice Over Internet Protocol (VoIP),
and also support live web-camera feed streaming, and multimedia content sharing (Gegenfurtner
et al., 2020). This kind of technological services, which are continuously researched and evaluated,
have been proven to increase student engagement, therefore highlighting that VLEs are currently
the best alternative to in-person learning (Caprara & Caprara, 2021; Kiss, 2012; Shamir-Inbal &
Blau, 2021; Zhang et al., 2004). With VLE infrastructure and wide-spread usage already in place,
the diffusion of immersive technologies, brought by the commercial re-invigoration of Virtual
Reality (VR) as recently as seven years ago (Zezulka et al., 2022), is bound to provide its own niche
for learning. Specifically, the necessity for Virtual Reality Learning Environments (VRLEs) became
evident during the COVID-19 mandatory lockdowns when distance learning substituted classrooms
and in-person learning worldwide (Singh et al., 2020) since for children in primary and secondary
education and university and college students the entire 2020?2021 academic year was in jeopardy
(Mseleku, 2020).
Several studies are reporting the positive impact VRLEs have on students’ engagement and performance compared to other non-immersive learning approaches (Vergara-Rodriguez et al.; Wu
et al., 2020), while others focus on usability issues examining the effects of equipment such as
Head Mounted Displays (HMDs), Controllers and Motion Tracking techniques on the learning experience provided through VRLEs (Kavanagh et al., 2017). One crucial aspect of the VR learning experience is the utilization of multi-user VRLEs, as shared spaces or virtual worlds wherein students and
educators have extensive control over 3D individual avatars. Studies on multi-user VRLEs and avatar
representation are also reporting enhanced engagement and performance (O’Connor et al., 2018;
Schild et al., 2018).
In addition to the above, evolvement of immersive technologies is now looking into incorporation of real-time body motion and gaze, as well as high-fidelity avatars by development of realtime facial cue capture (Chague & Charbonnier, 2016; Roth et al., 2019). That attention is mostly
driven by the importance of NVCs in face-to-face interpersonal communication (Archer & Akert,
1977), which is considered equally crucial in virtual worlds (Roth et al., 2016; Smith & Neff,
2018). Integration of NVCs onto both avatars and non-player characters (NPCs) contribute to
their realism (Latoschik et al., 2017; Maloney et al., 2020) in addition to being an important communication tool in multi-user virtual worlds. However, detailed NVC transference from real to
virtual world is, in most cases, semi-automated (e.g. support of pre-defined body gestures, automated facial expressions, and lip synching, etc.). With such methods, NVCs are used as flavour
rather than invaluable signals of the communicative process and therefore affect both overall
realism (Tanenbaum et al., 2020) and social/interpersonal engagement. The latter is of great
importance in VRLEs where social and behavioural cues are an integral part of the learning
process, while their lack makes communication over collaborative tasks in VRLEs more challenging
(Ripka et al., 2020).
Scarce examples of NVCs incorporation in VRLEs indicate their potential in enhancing the quality
of the learning experience. For example, allowing students to control their virtual body in VRLEs
increases their immersion and enjoyment compared to conventional VLEs (Zizza et al., 2018). Moreover, solving real facial expressions to a professor’s avatar can help hold student attention, and thus
improve knowledge acquisition, especially when the virtual lectures involve complicated language
(Theonas et al., 2008).
Nevertheless, those VRLE examples feature limited NVCs. Zizza et al. (2018) and Ripka et al.
(2020) allow students and professors to control a virtual body, but gaze motion and facial
expressions are not supported, while Theonas et al. (2008) allows students to only observe the
face expressions of a virtual professor who however lacks body motion whereas intercommunication is also not possible as the lectures are pre-recorded. Considering the scarcity and drawbacks of
the VRLEs incorporating detailed NVCs, our work aims toward shedding light into the effect of their
integration to the learning experience. In detail, the VRLE investigated here differentiates from
others in terms of using a high-fidelity avatar representing the real professor in the virtual
world. The professor’s avatar features detailed NVCs such as facial expressions, full body motion,
including finger motion which allows for detailed gestures, and gaze motion, all tracked and delivered to students in real time. This setup allows for higher avatar NVCs fidelity compared to the
systems presented above.
The aim of this study is investigation of NVCs effects on the learning experience via the VRLE prototype, whilst simultaneously gaining valuable insight as to the technological practicalities and challenges of incorporating such modalities in VR systems. The objectives set to evaluate the VRLE’s
usability, level of realism, and usefulness, and investigate its overall adequacy as an educational
tool compared to conventional VLEs such as the BBB.

Methods
Study design and participants
The VRLE developed for this study was evaluated by 20 post-graduate students (12 Female, 8 Male),
between 23 and 55 years old, who were attending the same MSc programme. The educational
content that helped with the VRLE’s evaluation is the final part of an actual lecture that is taught
each year as part of the course’s official curriculum. Based on the existing syllabus, on the day of
the evaluation, students were taught about User Interfaces (UIs) in games (Raffaele et al., 2017) featuring integrated multimedia content.
Typically, students audit this course via BBB since the entire MSc programme is remote. The final
part of the two-hour lecture is approximately 30 min in length, and students were provided with a
link that allowed them to install the VRLE and audit this part of the lecture in real-time, whilst the
professor’s body motion, facial expressions, and gaze were motion captured during his actual presentation and solved onto his avatar.
In addition, another 20 students (10 Female, 10 Male) of the same MSc programme, between 24
and 50 years old audited the same exact lecture, and the same exact examples, but only via their
typical BBB modalities. More specifically, screenshots of the same VRLE were used to exemplify
the lecture’s content, but that group of students was not able to navigate a virtual space in realtime or watch the professor’s avatar roam and spatially organize interface-related information in
three-dimensions.
System architecture
To develop the VRLE presented in this work we integrated, and customized when required, a variety
of off-the-shelf technologies. The core of the system consists of a VR Ready PC, a VIVE Pro HMD
[https://www.vive.com/us/product/], and two (2) base stations used to track its location in the real
world. Additionally, five (5) VIVE Trackers [https://www.vive.com/us/accessory/vive-tracker/] were
used to track the motion of the pelvis, hands, and feet of a real professor. Combining VIVE Pro
HMD and VIVE Trackers with the Inverse Kinematics (IK) solution Final IK [http://root-motion.com/
], allowed me to transfer the full body motion of the real professor to his avatar in real time. The
overall development of the system was completed using Unity [https://unity.com/], while the
avatar representing the real professor in the virtual world was designed using Character Creator
[https://www.reallusion.com/].
To track the professor’s finger-motion the ManusVR Gloves [https://manus-vr.com/] were utilized.
Finger tracking, when using the ManusVR Unity SDK, was not optimal as several inconsistencies were
documented. Therefore, additional code had to be authored to include rotation coefficient offsets for
each finger’s rotational data provided by the ManusVR Gloves, to appropriately transfer finger
rotation to the professor’s avatar. The capture of the professor’s facial expressions required two separate solutions. The Pupil Labs Eye Tracking [https://pupil-labs.com/] was used to capture eyemotion, therefore direction of gaze, which was then transferred to the professor’s avatar, whereas
BinaryVR [https://www.hyprsense.com/] captured, through an infrared camera, motions of the
mouth and lower jaw and transferred them onto the professor’s avatar via an array of BlendShapes
[https://docs.unity3d.com/Manual/BlendShapes.html]. By this, aside from capturing any grimaces,
which are regarded as NVCs, mouth movements matched and were accurately synchronized
between the professor and the avatar, enhancing overall realism of delivery.
The BinaryVR Unity’s SDK includes an example for transferring facial expressions data onto the
face of an avatar through blendshapes. However, the model provided by Binary is custom-made
and unsuitable for solving tracked facial expressions onto other 3D human models. To address
this issue, the correspondence between blendshape data provided by the BinaryVR SDK and
those of the professor’s avatar had to be calibrated accordingly to match differences in the 3D
model structure. Then, a custom script was utilized to create a float coefficient for each blendshape.
By manipulating each coefficient using a slider, while multiplying it with the corresponding blendshape data provided by BinaryVR, we was able to calibrate any facial expressions offsets, matching
the facial expressions of the professor in the real-world with the ones of his avatar in the virtual world
(see Figure 1).
The next step of the system’s development process was synchronization between the data from
the professor’s VR Ready PC and the desktop clients used by the students who were watching and
participating in the lecture. To do so, Mirror [https://mirror-networking.com/] (TCP Server in C#) was
assisted in keeping the overall data packed as small as possible. More specifically, to ensure smoothness in the avatar’s motion, all sensor data collected from the tracking devices (628 bytes) had to be
sent in each Transmission Control Protocol (TCP) packet. High-speed synchronization was ensured
because this packet is half the safe size limit of Mirror (Figure 2).
The finalized system allowed remote students to connect and roam around a shared virtual world,
as well as attend the lecture taking place inside the virtual environment, by using their personal
desktop/laptop computers (see Figure 3(a)). As mentioned elsewhere, one of the objectives was
the evaluation of the avatar’s high-fidelity impact on the overall learning experience facilitated by
the VRLE. Therefore, students had their own avatars, but those were minimal featuring simple
disk-shaped 3D models, drawing most of the focus toward the professor’s more complex and sophisticated avatar. Also, each student avatar was equipped with a camera, which could be rotated using
a mouse, and placed at a proper height to allow them to observe the virtual world at a fixed eye level.
This way we provided a sense of location for each student in relation to the others in the virtual
world, ensured their ability to maintain eye contact with the professor (see Figure 3(b)), and
avoided distractions. Moreover, students could communicate with each other as well as the professor via VoIP.
Finally, as mentioned above, the lectures’ content was dedicated to UIs in games. Therefore, the
particular environment students witnessed inside the VRLE was specifically designed to showcase
concepts of UIs in games, such as the differences between diegetic, non-diegetic, spatial, and
meta-user interfaces, etc (Raffaele et al., 2017). The elements used as “props” of the lecture were
specifically designed for that course and allowed the professor to perform sophisticated actions
such as pointing to enlarged, 3D UI elements (see Figure 3(c,d)).

Data collection
Once the lecture was completed students experiencing the VRLE were given an online questionnaire,
40 items of which were based on a five-point Likert scale (1 = Strongly Disagree, 2 = Disagree, 3 =
Neutral, 4 = Agree, 5 = Strongly Agree), and four (4) additional open-ended questions. More specifically, the first set of questionnaire items (9 questions) examines distance learning in general, and
how the COVID-19 social distancing restrictions have impacted the learning process. The second
set of questionnaire items (31) refers to the VRLE that the students had just experienced, and
those items are further divided into sets of questions regarding usability, realism, and usefulness
of the VRLE, along with questions regarding NVCs effect on the learning experience. The
questionnaire’s design, exploring various aspects of a VRLE experience, was adjusted by following
the example of past studies and their respective methodologies and inquiries. Specifically, questions
about COVID-19 and social restriction’s impact on the learning process were based on ArmstrongMensah et al. (2020) and Amir et al. (2020); usability questions were adapted from, while usefulness
and NVCs effect on the learning experience questions were adapted from Huang et al. (2010) and
Theonas et al. (2008), respectively.
Both the group of 20 students who followed the lecture via the VRLE and the other 20 who followed it only via the BBB on another occasion, were individually tasked with designing a game the UI
of which would incorporate and/or implement the entirety of the visual components that were presented and explained to them; specifically, their design should work with diegetic, non-diegetic,
spatial, meta, and heads-up display user interface components (Raffaele et al., 2017). Each submitted
assignment was individually evaluated and marked by the professor, but group averages were
specifically compared to one another, to establish whether the VRLE had any significant impact to
student knowledge acquisition and subsequent performance.
In addition to all the aspects reviewed and evaluated as mentioned above, the professor who conducted the lecture was also interviewed. The interview consisted of open-ended questions regarding
levels of comfort, ease in delivery, navigation, general impressions of the experience and so forth.

Ethical considerations
MSc attendance is mandatory therefore auditing the lecture is non-optional as part of the official
student curriculum. However, their participation in the evaluation process and therefore submission
of the distributed questionnaire is voluntary and independent from credits associated with their
overall performance. That being said, all students were eager to participate and willingly provided
the research team with their answers.
The institution facilitating both the MSc and the laboratory conducting this research does not
mandate approval by its Ethics Committee for human participants who are of age. As a general practice however, all experiments and evaluations conducted by the research team require participants
to sign a consent form. Since the MSc is remotely run, and additionally, the evaluation took place
during mandatory lockdowns, for this particular study the students, as participants to the research,
confirmed one by one to understand the parameters of their participation and provided their
consent verbally whilst their statement was being screen-recorded by a researcher.
Students were aware that an evaluation will be conducted via questionnaires upon completion of
the lecture and naturally some of them would be potentially participating. However, their participation was not disclosed to one another. Their overall anonymity is ensured since there are no identifiers from any of the data collected. The lecture as a whole was not screen-recorded. Still, during the
lecture and aside from the professor’s avatar, none of the other models were identifiable as to who is
the handler and therefore individual virtual actions were not associated with any particular person. In
simple words, neither the students nor the professor could identify who is who in the VRLE as all
models were the same. All intercommunication that took place during the virtual lecture (e.g. questions asked and answered) was no different from the typical communication during BBB remote lectures as the professor could correlate any voice to any specific student avatar.


Evaluation results
This section presents questionnaire results, discussing in detail each set of items. The questionnaire
data collected are treated as ordinal, relying on median values to reveal central tendencies along
with standard deviation - SD (Sullivan & Artino Jr, 2013). Questionnaire results are followed by the
knowledge acquisition evaluation which, as mentioned, was based on a comparison of average
group performance on the assignment given and individually submitted by and scored for each
student at the end of the academic term. The section concludes with the professor’s evaluation
of the experience, derived from the semi-structured interview transcripts.


Distance learning
Prior to evaluating the specifics of the VRLE presented here, students were asked to evaluate distance learning in general, and the extent to which the COVID-19 pandemic had impacted their interest in attending the MSc programme and their expected learning experience. The MSc provided was
a hybrid learning programme even prior to the pandemic, combining in person crash courses at the
beginning of each semester with weekly synchronous e-courses via the BBB platform. However,
during the mandatory lockdowns crash courses were cancelled and the entirety of the programme
was carried out long-distance.
As shown by the evaluation results, student’s interest towards attending the MSc programme was
affected by neither the Covid-19 restrictions (see Table 1 ? Q1), nor the in-person learning specific
restrictions (see Table 1 ? Q2). Moreover, according to students, the absence of in-person meetings
did not reduce the overall quality of the MSc programme (see Table 1 ? Q3). Nevertheless, the ability
of distance learning to replace in-person learning is questionable (see Table 1 ? Q4), showcasing that
the experience provided by it is hard to substitute despite the existence of high-quality distance
learning tools. Lectures provided through tools like BBB can help create a classroom-like environment for students (see Table 1 ? Q5), addressing to an extent their feelings of isolation during
online lectures (see Table 1 ? Q6). Students also confirmed that online lectures can adequately
provide them with all the content required to understand a subject (see Table 1 ? Q7), whilst
being able to see the teacher’s movements and facial expressions, therefore their NVCs, via the
web camera of the BBB helps them further understand the lecture’s content and maintain their
attention during lectures (see Table 1 ? Q8 and Table 1 ? Q9).
Overall, the evaluation results presented here indicate that distance learning and tools like BBB
are invaluable to students, allowing them to fully understand a subject while reducing their feelings
of isolation. While such tools cannot fully replace in-person learning, they provide an adequate
alternative which can assist towards overcoming difficulties such as the Covid-19 pandemic lockdown restrictions, allowing the learning process to progress uninterrupted. Furthermore, observing
professors NVCs through a web camera during lectures taking place remotely is of increased importance to students, adding to the learning experience quality.

Usability and realism
As already mentioned in Section 2, one of the objectives of this study is to evaluate the usability of
the VRLE presented here as it features unique characteristics compared to other VRLEs, such as the
integration of a high-fidelity avatar for the professor. During the lecture provided through the VRLE,
the average internet connection speed of the participants was 23mbps, average ping was 50ms, and
the average performance of the application was 148 frames per second (FPS).
According to student responses, the VRLE functioned properly without any serious errors (see
Table 2 ? Q1), allowing them to easily navigate through the virtual environment (see Table 2 ?
Q2). The graphical elements of the virtual environment were comprehensible and clear (see Table
2 ? Q3), while the professor’s motion was seamless without any interruptions (see Table 2 ? Q4).
More specifically, students could clearly observe and follow the body motion of the virtual professor
(see Table 2 ? Q5) but faced minor difficulties when observing and following the professor’s gaze
(see Table 2 ? Q6), focal point (see Table 2 ? Q7), and finger motion/gestures (see Table 2 ? Q8). This
incident occurred to six out of the twenty students evaluating the VRLE. When asked to elaborate,
those students noted that periodic latency occurred during the learning experience, slightly dropping the refresh rate of the virtual professor’s gaze and finger motion. However, four (4) out of
those five (5) students’ equipment was of low-end, featuring an average performance of 46 FPS,
whereas four (4) out of those six (5) students featured slow internet connection speeds with an
average of 10Mbps. The absence of difficulties when following the virtual professors gaze and
finger motion/gestures in the rest of the students (15) featuring both increased FPS and internet connection speeds clearly shows that those metrics are of high importance for the performance of VRLEs
incorporating high fidelity avatars featuring detailed NVCs. As noted by three (3) of those students,
another factor affecting their ability to observe and follow the virtual professor’s gaze and finger
motion was the use of a small display, which prohibited them from clearly observing those
aspects at all times during the lecture.
Continuing, the virtual professor’s voice quality was appreciated by all participants (see Table 2 ?
Q9), and was perceived in sync with his overall body motion (see Table 2 ? Q10). Minor latency incidents occurred in the synchronization of the virtual professor’s voice and facial expressions (see
Table 2 ? Q11), reducing their clarity to students as well (see Table 2 ? Q12). Again, most of those
incidents occurred to students equipped with low-end equipment, small displays, and slow internet
connection speeds. All in all, the avatar fidelity sufficed for students to understand his emotional
state in the virtual world (see Table 2 ? Q13) and follow his directions when required (see Table 2
? Q14).
The questionnaire items, as presented in Table 3, examine the level of the VRLE realism. As already
mentioned in Section 2, humans can observe the slighted inaccuracies in a virtual world, affecting
both their immersion and its overall level of realism. In the VRLE presented here, students appreciated the fidelity of the virtual professor’s motion and facial expressions (see Table 3 ? Q1). Moreover,
the virtual professor’s body and finger motion added to the overall realism of the VRLE (see Table 3 ?
Q2). The same occurred for the incorporation of both the virtual professor’s facial expressions (see
Table 3?Q3) and gaze direction which increased the overall realism of the experience as well (Table 3
? Q4). Those results indicate that the incorporation of such NVCs in a VRLE can assist toward increasing its overall level of realism and subsequently the quality of the overall experience it prov













